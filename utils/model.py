# utils/model.py

import os
import base64
from openai import OpenAI
from typing import List, Dict, Any

# é»˜è®¤é…ç½® - å®é™…ä½¿ç”¨æ—¶ä¼šä»config.jsonåŠ è½½
DEFAULT_BASE_URL = "https://ark.cn-beijing.volces.com/api/v3"
DEFAULT_MODEL = "your-model-name"

class LVMChat:
    """æ”¯æŒä¼šè¯è®°å¿†çš„å¤šæ¨¡æ€èŠå¤©ç±»"""
    
    def __init__(self, api_key: str = None, base_url: str = DEFAULT_BASE_URL, 
                 model: str = DEFAULT_MODEL):
        if not api_key:
            raise ValueError("API Key is required. Please configure it in config.json")
        self.client = OpenAI(api_key=api_key, base_url=base_url)
        self.model = model
        # ğŸ”¥ æ ¸å¿ƒæ”¹åŠ¨ï¼šæ·»åŠ ä¼šè¯å†å²è®°å½•
        self.conversation_history: List[Dict[str, Any]] = []
    
    def _encode_image(self, image_path: str) -> str:
        """å°†æœ¬åœ°å›¾ç‰‡è½¬ä¸º data URLï¼Œæ–¹ä¾¿ç›´æ¥ä½œä¸º image_url ä¼ å…¥"""
        with open(image_path, "rb") as image_file:
            b64 = base64.b64encode(image_file.read()).decode("utf-8")
        return f"data:image/jpeg;base64,{b64}"
    
    def get_multimodal_response(self, text: str, image_paths: str, 
                                res_format: str = "text", use_history: bool = False) -> tuple[str, dict]:
        """
        æ”¯æŒè®°å¿†çš„å›¾æ–‡å¯¹è¯
        
        Args:
            text: ä½ çš„é—®é¢˜
            image_paths: å›¾ç‰‡è·¯å¾„
            res_format: å“åº”æ ¼å¼ ("text" æˆ– "json")
            use_history: æ˜¯å¦ä½¿ç”¨ä¼šè¯å†å²ï¼ˆè®°ä½ä¹‹å‰çš„å¯¹è¯ï¼‰
            
        Returns:
            (response_text, usage_info): å“åº”æ–‡æœ¬å’Œä½¿ç”¨ç»Ÿè®¡
        """
        # 1. åŠ è½½å›¾ç‰‡å¹¶è½¬ä¸º Ark æ”¯æŒçš„ data URL
        image_url = self._encode_image(image_paths)
        
        # 2. æ„å»º inputï¼ˆArk Responses APIï¼‰
        current_message = {
            "role": "user",
            "content": [
                {"type": "input_image", "image_url": image_url},
                {"type": "input_text", "text": text},
            ],
        }
        
        # 3. ğŸ”¥ å…³é”®ï¼šå¦‚æœå¯ç”¨å†å²ï¼ŒæŠŠä¹‹å‰çš„å¯¹è¯ä¹Ÿå¸¦ä¸Š
        if use_history and self.conversation_history:
            # å¯¹äºæœ‰å†å²çš„æƒ…å†µï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
            payload = self.conversation_history + [current_message]
            print(f"ğŸ“š ä½¿ç”¨å†å²ä¸Šä¸‹æ–‡ï¼Œå…± {len(self.conversation_history)} æ¡")
            
            # è°ƒç”¨ API (ä½¿ç”¨chat.completionsè€Œä¸æ˜¯responses)
            try:
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=self._convert_to_chat_format(payload)
                )
                result = response.choices[0].message.content
                
                # æå–tokenä½¿ç”¨ä¿¡æ¯
                usage_info = {
                    'input_tokens': getattr(response.usage, 'prompt_tokens', 0) if hasattr(response, 'usage') else 0,
                    'output_tokens': getattr(response.usage, 'completion_tokens', 0) if hasattr(response, 'usage') else 0,
                    'total_tokens': getattr(response.usage, 'total_tokens', 0) if hasattr(response, 'usage') else 0
                }
            except Exception as e:
                print(f"Chat API failed, falling back to responses API: {e}")
                # å›é€€åˆ°å•æ¬¡è°ƒç”¨
                response = self.client.responses.create(
                    model=self.model,
                    input=[current_message]
                )
                result = getattr(response, "output_text", str(response))
                usage_info = {'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0}
        else:
            payload = [current_message]
            # 4. è°ƒç”¨ API
            response = self.client.responses.create(
                model=self.model,
                input=payload
            )
            result = getattr(response, "output_text", str(response))
            
            # å°è¯•ä»å“åº”ä¸­æå–tokenä¿¡æ¯ï¼ˆå¦‚æœAPIæä¾›ï¼‰
            usage_info = {
                'input_tokens': getattr(response, 'input_tokens', 0) if hasattr(response, 'input_tokens') else 0,
                'output_tokens': getattr(response, 'output_tokens', 0) if hasattr(response, 'output_tokens') else 0,
                'total_tokens': 0
            }
            usage_info['total_tokens'] = usage_info['input_tokens'] + usage_info['output_tokens']
        
        # 6. ğŸ”¥ æ›´æ–°å†å²è®°å½•
        if use_history:
            self.conversation_history.append(current_message)
            self.conversation_history.append({
                "role": "assistant", 
                "content": [{"type": "output_text", "text": result}]
            })
        
        return result, usage_info
    
    def clear_history(self):
        """æ¸…ç©ºè®°å¿†"""
        self.conversation_history = []


# # ç¤ºä¾‹è°ƒç”¨
# if __name__ == "__main__":
#     chat = LVMChat()
#     response = chat.get_multimodal_response(
#         text="è¿™å¼ å›¾ç‰‡é‡Œè¾“å…¥æ¡†åæ ‡ï¼Ÿ",
#         image_paths=r"D:\projects\cc\GUI-Agent\utils\screenshot-20260120-160656.png"
#     )
#     print(response)


# ä¼šè¯è®°å¿†ç¤ºä¾‹
#  # ç¬¬ä¸€è½®å¯¹è¯
# conversation_history = [
#     {"role": "user", "content": [å›¾ç‰‡1, "åœ¨è¾“å…¥æ¡†è¾“å…¥â€˜ä½ å¥½â€™"]},
#     {"role": "assistant", "content": "{'Thought'ï¼š 'è¾“å…¥æ¡†åœ¨é¡µé¢ä¸­é—´ä½ç½®ï¼Œæˆ‘éœ€è¦è¾“å…¥æ–‡æ¡ˆ', 'Action': 'type(content=\'ä½ å¥½\')'}"}
# ]

# # ç¬¬äºŒè½®å¯¹è¯æ—¶ï¼ŒæŠŠå†å²ä¹Ÿå¸¦ä¸Š
# messages = conversation_history + [
#     {"role": "user", "content": [å›¾ç‰‡2, "åœ¨è¾“å…¥æ¡†è¾“å…¥â€˜ä½ å¥½â€™"]}
# ]
# # ç°åœ¨AIèƒ½çœ‹åˆ°å®Œæ•´çš„å¯¹è¯é“¾ï¼ŒçŸ¥é“è‡ªå·±åšè¿‡ä»€ä¹ˆå†³ç­–ã€‚åœ¨ç¬¬äºŒè½®è¿”å›:
# {'Thought'ï¼š 'ä¸Šä¸€è½®å·²ç»å®Œæˆè¾“å…¥æ“ä½œå¹¶ä¸”æ–‡æ¡ˆå·²ç»æ­£ç¡®æ˜¾ç¤ºåœ¨è¾“å…¥æ¡†ï¼Œä»»åŠ¡å·²ç»å®Œæˆ', 'Action': 'finished'}
    
    def _convert_to_chat_format(self, payload):
        """å°†Ark responsesæ ¼å¼è½¬æ¢ä¸ºchatæ ¼å¼"""
        messages = []
        for item in payload:
            if item["role"] == "user":
                # è½¬æ¢ç”¨æˆ·æ¶ˆæ¯
                content = []
                for c in item["content"]:
                    if c["type"] == "input_image":
                        content.append({
                            "type": "image_url",
                            "image_url": {"url": c["image_url"]}
                        })
                    elif c["type"] == "input_text":
                        content.append({
                            "type": "text", 
                            "text": c["text"]
                        })
                messages.append({
                    "role": "user",
                    "content": content
                })
            elif item["role"] == "assistant":
                # è½¬æ¢åŠ©æ‰‹æ¶ˆæ¯
                text_content = ""
                for c in item["content"]:
                    if c["type"] == "output_text":
                        text_content = c["text"]
                        break
                messages.append({
                    "role": "assistant",
                    "content": text_content
                })
        return messages